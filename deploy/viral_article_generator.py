#!/usr/bin/env python3
"""
Viral Article Generator
ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æçµæœã«åŸºã¥ã„ã¦ãƒã‚¤ãƒ©ãƒ«ã«ãªã‚Šã‚„ã™ã„è¨˜äº‹ã‚’è‡ªå‹•ç”Ÿæˆ
"""

import os
import sys
import json
import logging
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import random
import hashlib

# Add current directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ranking_analyzer import NewsRankingAnalyzer

try:
    from deepseek_processor import DeepSeekProcessor
except ImportError:
    DeepSeekProcessor = None

logger = logging.getLogger(__name__)

class ViralArticleGenerator:
    def __init__(self):
        self.ranking_analyzer = NewsRankingAnalyzer()
        self.deepseek_client = DeepSeekProcessor() if DeepSeekProcessor else None
        self.generated_articles = []
        
    def generate_trending_articles(self, num_articles: int = 5) -> List[Dict]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ã„ãŸè¨˜äº‹ã‚’è‡ªå‹•ç”Ÿæˆ"""
        
        logger.info("ğŸ”¥ Starting viral article generation...")
        
        # ç¾åœ¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°åé›†
        current_rankings = self.ranking_analyzer.collect_all_rankings()
        
        # ãƒã‚¤ãƒ©ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        viral_patterns = self.ranking_analyzer.identify_viral_patterns()
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒˆãƒƒãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰è¨˜äº‹ç”Ÿæˆ
        generated_articles = []
        categories = ['ã‚¨ãƒ³ã‚¿ãƒ¡', 'ã‚¹ãƒãƒ¼ãƒ„', 'ç·åˆ', 'ç¤¾ä¼š', 'IT']
        
        for i in range(min(num_articles, len(categories))):
            category = categories[i]
            
            # ãã®ã‚«ãƒ†ã‚´ãƒªã§æœ€ã‚‚äººæ°—ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—
            hot_keywords = [
                kw.split(':', 1)[1] for kw, score in viral_patterns['hot_keywords'] 
                if kw.startswith(f"{category}:")
            ][:5]
            
            if not hot_keywords:
                # ã‚«ãƒ†ã‚´ãƒªå›ºæœ‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯æ±ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                hot_keywords = ['é€Ÿå ±', 'è¡æ’ƒ', 'è©±é¡Œ', 'æ³¨ç›®', 'ç™ºè¡¨']
            
            # è¨˜äº‹ç”Ÿæˆ
            try:
                article = self.generate_viral_article(category, hot_keywords, viral_patterns)
                if article:
                    generated_articles.append(article)
                    logger.info(f"âœ… Generated article for {category}: {article['title']}")
            except Exception as e:
                logger.error(f"Error generating article for {category}: {e}")
                continue
        
        self.generated_articles = generated_articles
        return generated_articles
    
    def generate_viral_article(self, category: str, keywords: List[str], patterns: Dict) -> Optional[Dict]:
        """ã‚«ãƒ†ã‚´ãƒªã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦è¨˜äº‹ã‚’ç”Ÿæˆ"""
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = self.create_viral_prompt(category, keywords, patterns)
        
        # DeepSeekã§è¨˜äº‹ç”Ÿæˆï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼è¨˜äº‹ã‚’ç”Ÿæˆï¼‰
        try:
            if self.deepseek_client:
                article_data = self.deepseek_client.process_news(prompt)
                
                if article_data and 'articles' in article_data and article_data['articles']:
                    article = article_data['articles'][0]
                    
                    # è¨˜äº‹IDã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    article['id'] = self._generate_article_id(article['title'])
                    article['category'] = category
                    article['generated_at'] = datetime.now(timezone.utc).isoformat()
                    article['viral_keywords'] = keywords
                    article['is_generated'] = True
                    article['source'] = 'AI Generated (Viral Pattern Analysis)'
                    article['url'] = f"#article-{article['id']}"
                    article['reliability_score'] = 0.7  # AIç”Ÿæˆè¨˜äº‹ãªã®ã§ä¸­ç¨‹åº¦ã®ä¿¡é ¼æ€§
                    
                    return article
                else:
                    logger.warning(f"No article generated for {category}")
                    return None
            else:
                # DeepSeekã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼è¨˜äº‹ã‚’ç”Ÿæˆ
                return self._generate_dummy_article(category, keywords)
                
        except Exception as e:
            logger.error(f"Error in generate_viral_article: {e}")
            return None
    
    def create_viral_prompt(self, category: str, keywords: List[str], patterns: Dict) -> str:
        """ãƒã‚¤ãƒ©ãƒ«è¨˜äº‹ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆã‹ã‚‰æœ€ã‚‚åŠ¹æœçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        top_patterns = []
        if patterns['title_patterns']:
            pattern_items = sorted(patterns['title_patterns'].items(), key=lambda x: x[1], reverse=True)
            top_patterns = [p[0] for p in pattern_items[:3]]
        
        # æ„Ÿæƒ…ãƒˆãƒªã‚¬ãƒ¼ã®ä¸Šä½ã‚’å–å¾—
        top_emotions = []
        if patterns['emotion_triggers']:
            emotion_items = sorted(patterns['emotion_triggers'].items(), key=lambda x: x[1], reverse=True)
            top_emotions = [e[0] for e in emotion_items[:2]]
        
        # ã‚¿ã‚¤ãƒˆãƒ«é•·ã®æ¨å¥¨
        title_length = patterns['optimal_length']
        optimal_length = title_length.get('optimal', 40) if title_length else 40
        
        prompt = f"""
ä»¥ä¸‹ã®æ¡ä»¶ã§{category}ã‚«ãƒ†ã‚´ãƒªã®ãƒã‚¤ãƒ©ãƒ«ã«ãªã‚Šã‚„ã™ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’1ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å¿…é ˆæ¡ä»¶ã€‘
- ã‚«ãƒ†ã‚´ãƒª: {category}
- ä½¿ç”¨ã™ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords[:3])}
- ã‚¿ã‚¤ãƒˆãƒ«æ–‡å­—æ•°: {optimal_length-5}ã€œ{optimal_length+5}æ–‡å­—

ã€ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«ã€‘
"""
        
        if 'bracket_emphasis' in top_patterns:
            prompt += "- å¿…ãšã€ã€‘ã§é‡è¦éƒ¨åˆ†ã‚’å¼·èª¿ã™ã‚‹\n"
        if 'number_usage' in top_patterns:
            prompt += "- å…·ä½“çš„ãªæ•°å­—ã‚’å«ã‚ã‚‹ï¼ˆå¹´é½¢ã€é‡‘é¡ã€é †ä½ã€ï¼…ãªã©ï¼‰\n"
        if 'quote_usage' in top_patterns:
            prompt += "- ã€Œã€ã§å°è±¡çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã™ã‚‹\n"
        if 'question_form' in top_patterns:
            prompt += "- ç–‘å•å½¢ã§èª­è€…ã®èˆˆå‘³ã‚’å¼•ã\n"
        
        prompt += f"""
- æ„Ÿæƒ…ã‚’æºã•ã¶ã‚‹ï¼ˆç‰¹ã«{', '.join(top_emotions)}ã®æ„Ÿæƒ…ï¼‰
- ä»Šè©±é¡Œã«ãªã‚Šãã†ãªå†…å®¹ã«ã™ã‚‹

ã€æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ä¾‹ã€‘
"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ä¾‹
        if category == 'ã‚¨ãƒ³ã‚¿ãƒ¡':
            prompt += """
- ã€è¡æ’ƒã€‘ä¿³å„ªA(28)ãŒé›»æ’ƒçµå©šï¼ãŠç›¸æ‰‹ã¯20ä»£ãƒ¢ãƒ‡ãƒ«
- ã€é€Ÿå ±ã€‘äººæ°—ã‚¢ã‚¤ãƒ‰ãƒ«BãŒæ¶™ã®å‘Šç™½ã€Œã‚‚ã†é™ç•Œã§ã—ãŸã€
- ã€ç‹¬å ã€‘å¤§ç‰©èŠ¸äººCã®ä¸å€«ç–‘æƒ‘ã€æœ¬äººãŒæ¿€ç™½
"""
        elif category == 'ã‚¹ãƒãƒ¼ãƒ„':
            prompt += """
- ã€é€Ÿå ±ã€‘æ—¥æœ¬ä»£è¡¨é¸æ‰‹DãŒæµ·å¤–ç§»ç±ï¼å¹´ä¿¸ã¯æ¨å®š5å„„å††
- ã€è¡æ’ƒã€‘äººæ°—é¸æ‰‹EãŒå¼•é€€è¡¨æ˜ã€Œä½“åŠ›ã®é™ç•Œã€
- ã€æ­“å–œã€‘æ—¥æœ¬ãƒãƒ¼ãƒ ãŒæ­´å²çš„å‹åˆ©ï¼ç›£ç£ãŒæ¶™
"""
        elif category == 'IT':
            prompt += """
- ã€é©å‘½ã€‘æ–°AIæŠ€è¡“ã§å¹´å1000ä¸‡å††ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒæ€¥å¢—
- ã€è­¦å‘Šã€‘äººæ°—ã‚¢ãƒ—ãƒªã«é‡å¤§ãªè„†å¼±æ€§ï¼å€‹äººæƒ…å ±æµå‡ºã®æã‚Œ
- ã€ç‹¬å ã€‘å¤§æ‰‹ITä¼æ¥­ãŒæ–°ã‚µãƒ¼ãƒ“ã‚¹ç™ºè¡¨ã€æ¥­ç•Œæ¿€éœ‡
"""
        else:
            prompt += """
- ã€é€Ÿå ±ã€‘æ”¿åºœãŒæ–°åˆ¶åº¦ã‚’ç™ºè¡¨ã€å›½æ°‘ç”Ÿæ´»ã«å¤§ããªå½±éŸ¿
- ã€è¡æ’ƒã€‘æœ‰åä¼æ¥­ãŒå€’ç”£å±æ©Ÿã€å¾“æ¥­å“¡1ä¸‡äººã®é‹å‘½ã¯
- ã€ç‹¬å ã€‘è©±é¡Œã®äº‹ä»¶ã€é–¢ä¿‚è€…ãŒçœŸç›¸ã‚’æ¿€ç™½
"""
        
        prompt += f"""

ã€è¨˜äº‹å†…å®¹ã®æ§‹æˆã€‘
1. ãƒªãƒ¼ãƒ‰æ–‡ï¼ˆ100-150æ–‡å­—ï¼‰
   - å†’é ­ã§æœ€ã‚‚è¡æ’ƒçš„ãªäº‹å®Ÿã‚’æç¤º
   - èª­è€…ã‚’å¼•ãè¾¼ã‚€å¼·ã„ãƒ•ãƒƒã‚¯
   
2. æœ¬æ–‡ï¼ˆ1000-1500æ–‡å­—ï¼‰
   - äº‹å®Ÿã¨æ¨æ¸¬ã‚’ç¹”ã‚Šäº¤ãœã‚‹
   - é–¢ä¿‚è€…ã®ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆæ¶ç©ºã§OKï¼‰ã‚’å«ã‚ã‚‹
   - å…·ä½“çš„ãªæ•°å­—ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†
   - æ™‚ç³»åˆ—ã§å±•é–‹ã‚’èª¬æ˜
   
3. ä»Šå¾Œã®å±•æœ›ï¼ˆ200æ–‡å­—ï¼‰
   - èª­è€…ãŒæ°—ã«ãªã‚‹ä»Šå¾Œã®å±•é–‹ã‚’ç¤ºå”†
   - ç¶šå ±ã¸ã®æœŸå¾…ã‚’æŒãŸã›ã‚‹

ã€æ³¨æ„äº‹é …ã€‘
- å®Ÿåœ¨ã®äººç‰©åã¯ä½¿ã‚ãšã€Aã€Bã€Cãªã©ã§è¡¨ç¾
- æ–­å®šçš„ãªè¡¨ç¾ã‚’ä½¿ã„ã€èª¬å¾—åŠ›ã‚’æŒãŸã›ã‚‹
- SNSã§ã®åå¿œã‚‚å«ã‚ã‚‹
- ç¾åœ¨ã®æ—¥ä»˜: {(datetime.now(timezone.utc) + timedelta(hours=9)).strftime('%Yå¹´%mæœˆ%dæ—¥')}

å¿…ãšJSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{{
    "articles": [{{
        "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
        "content": "è¨˜äº‹æœ¬æ–‡",
        "summary": "100æ–‡å­—ç¨‹åº¦ã®è¦ç´„",
        "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3"],
        "published": "2024-03-15T10:00:00Z",
        "language": "ja",
        "tone": "sensational"
    }}]
}}
"""
        
        return prompt
    
    def _generate_dummy_article(self, category: str, keywords: List[str]) -> Dict:
        """ãƒ€ãƒŸãƒ¼ã®ãƒã‚¤ãƒ©ãƒ«è¨˜äº‹ã‚’ç”Ÿæˆ"""
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ€ãƒŸãƒ¼ã‚¿ã‚¤ãƒˆãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        title_templates = {
            'ã‚¨ãƒ³ã‚¿ãƒ¡': [
                "ã€è¡æ’ƒã€‘äººæ°—ä¿³å„ªA(28)ãŒé›»æ’ƒçµå©šï¼ãŠç›¸æ‰‹ã¯20ä»£ãƒ¢ãƒ‡ãƒ«",
                "ã€é€Ÿå ±ã€‘å¤§ç‰©æ­Œæ‰‹BãŒæ´»å‹•ä¼‘æ­¢ã‚’ç™ºè¡¨ã€ãƒ•ã‚¡ãƒ³é¨’ç„¶",
                "ã€ç‹¬å ã€‘ç¾äººå¥³å„ªCã®ä¸å€«ç–‘æƒ‘ã€é–¢ä¿‚è€…ãŒæ¿€ç™½",
                "ã€æ‚²å ±ã€‘äººæ°—ã‚¢ã‚¤ãƒ‰ãƒ«DãŒæ¶™ã®å‘Šç™½ã€Œé™ç•Œã§ã—ãŸã€"
            ],
            'ã‚¹ãƒãƒ¼ãƒ„': [
                "ã€é€Ÿå ±ã€‘æ—¥æœ¬ä»£è¡¨ã‚¨ãƒ¼ã‚¹ãŒæµ·å¤–ç§»ç±ï¼å¹´ä¿¸ã¯æ¨å®š5å„„å††",
                "ã€è¡æ’ƒã€‘äººæ°—é¸æ‰‹FãŒå¼•é€€è¡¨æ˜ã€Œä½“åŠ›ã®é™ç•Œã€æ¶™ã®ä¼šè¦‹",
                "ã€æ­“å–œã€‘æ—¥æœ¬ãƒãƒ¼ãƒ ãŒæ­´å²çš„å‹åˆ©ï¼ç›£ç£ã€Œä¿¡ã˜ã‚‰ã‚Œãªã„ã€",
                "ã€ç‹¬å ã€‘ã‚¹ã‚¿ãƒ¼é¸æ‰‹Gã®ç§»ç±äº¤æ¸‰ã€èˆå°è£ã‚’é–¢ä¿‚è€…ãŒæ¿€ç™½"
            ],
            'IT': [
                "ã€é©å‘½ã€‘æ–°AIæŠ€è¡“ã§å¹´å1000ä¸‡å††ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒæ€¥å¢—ä¸­",
                "ã€è­¦å‘Šã€‘äººæ°—ã‚¢ãƒ—ãƒªã«é‡å¤§è„†å¼±æ€§ï¼å€‹äººæƒ…å ±æµå‡ºã®æã‚Œ",
                "ã€ç‹¬å ã€‘å¤§æ‰‹ITä¼æ¥­ãŒæ–°ã‚µãƒ¼ãƒ“ã‚¹ç™ºè¡¨ã€æ¥­ç•Œã«æ¿€éœ‡",
                "ã€é€Ÿå ±ã€‘è©±é¡Œã®AIã‚µãƒ¼ãƒ“ã‚¹ãŒçªç„¶åœæ­¢ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å¤§æ··ä¹±"
            ],
            'ç·åˆ': [
                "ã€é€Ÿå ±ã€‘æ”¿åºœãŒæ–°åˆ¶åº¦ç™ºè¡¨ã€å›½æ°‘ç”Ÿæ´»ã«å¤§ããªå½±éŸ¿ã‹",
                "ã€è¡æ’ƒã€‘æœ‰åä¼æ¥­ãŒçªç„¶å€’ç”£ã€å¾“æ¥­å“¡1000äººã®é‹å‘½ã¯",
                "ã€ç‹¬å ã€‘è©±é¡Œã®äº‹ä»¶ã€é–¢ä¿‚è€…ãŒè¡æ’ƒã®çœŸç›¸ã‚’æ¿€ç™½",
                "ã€ç·Šæ€¥ã€‘å¤§å‹å°é¢¨æ¥è¿‘ã€å°‚é–€å®¶ã€Œéå»æœ€å¤§ç´šã®è­¦æˆ’ã‚’ã€"
            ],
            'ç¤¾ä¼š': [
                "ã€ç™ºè¦šã€‘å¤§ä¼æ¥­ã®ä¸æ­£ä¼šè¨ˆã€æå¤±é¡ã¯100å„„å††è¦æ¨¡",
                "ã€é€Ÿå ±ã€‘æœ‰åæ”¿æ²»å®¶ã«æ±šè·ç–‘æƒ‘ã€æ¤œå¯ŸãŒæœ¬æ ¼æœæŸ»é–‹å§‹",
                "ã€è¡æ’ƒã€‘äººæ°—ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã§é£Ÿä¸­æ¯’ã€åŸå› ã¯å¾“æ¥­å“¡ã®è¡›ç”Ÿç®¡ç†",
                "ã€ç‹¬å ã€‘ç¤¾ä¼šå•é¡ŒåŒ–ã™ã‚‹äº‹ä»¶ã€è¢«å®³è€…å®¶æ—ãŒå¿ƒå¢ƒã‚’èªã‚‹"
            ]
        }
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’é¸æŠ
        templates = title_templates.get(category, title_templates['ç·åˆ'])
        title = random.choice(templates)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª¿æ•´
        if keywords:
            keyword = random.choice(keywords)
            if keyword not in title:
                # ã€ã€‘å†…ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                if 'ã€' in title and 'ã€‘' in title:
                    bracket_content = title.split('ã€')[1].split('ã€‘')[0]
                    title = title.replace(f'ã€{bracket_content}ã€‘', f'ã€{keyword}ã€‘')
        
        # ãƒ€ãƒŸãƒ¼è¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆ
        content = self._generate_dummy_content(category, title, keywords)
        
        article = {
            'id': self._generate_article_id(title),
            'title': title,
            'content': content,
            'summary': content[:100] + '...',
            'tags': keywords[:3] if keywords else ['ãƒ‹ãƒ¥ãƒ¼ã‚¹', category],
            'published': datetime.now(timezone.utc).isoformat(),
            'language': 'ja',
            'tone': 'sensational',
            'category': category,
            'generated_at': datetime.now(timezone.utc).isoformat(),
            'viral_keywords': keywords,
            'is_generated': True,
            'source': 'AI Generated (Pattern Analysis - Demo)',
            'url': f"#article-{self._generate_article_id(title)}",
            'reliability_score': 0.6
        }
        
        return article
    
    def _generate_dummy_content(self, category: str, title: str, keywords: List[str]) -> str:
        """ãƒ€ãƒŸãƒ¼ã®è¨˜äº‹å†…å®¹ã‚’ç”Ÿæˆ"""
        category_contexts = {
            'ã‚¨ãƒ³ã‚¿ãƒ¡': [
                "èŠ¸èƒ½ç•Œã«è¡æ’ƒãŒèµ°ã£ã¦ã„ã‚‹ã€‚",
                "é–¢ä¿‚è€…ã«ã‚ˆã‚‹ã¨ã€ã“ã®ç™ºè¡¨ã¯äºˆæƒ³å¤–ã ã£ãŸã¨ã„ã†ã€‚",
                "ãƒ•ã‚¡ãƒ³ã‹ã‚‰ã¯ç¥ç¦ã¨é©šãã®å£°ãŒç›¸æ¬¡ã„ã§ã„ã‚‹ã€‚",
                "æ‰€å±äº‹å‹™æ‰€ã‚‚æ­£å¼ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç™ºè¡¨ã—ãŸã€‚"
            ],
            'ã‚¹ãƒãƒ¼ãƒ„': [
                "ã‚¹ãƒãƒ¼ãƒ„ç•Œã§å¤§ããªè©±é¡Œã¨ãªã£ã¦ã„ã‚‹ã€‚",
                "ãƒãƒ¼ãƒ é–¢ä¿‚è€…ã¯ã€Œäºˆæƒ³ã—ã¦ã„ãªã‹ã£ãŸå±•é–‹ã€ã¨èªã‚‹ã€‚",
                "ãƒ•ã‚¡ãƒ³ã‚„é–¢ä¿‚è€…ã‹ã‚‰ã¯æ§˜ã€…ãªåå¿œãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã‚‹ã€‚",
                "ä»Šå¾Œã®å‹•å‘ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã‚‹ã€‚"
            ],
            'IT': [
                "ITæ¥­ç•Œã§å¤§ããªå‹•ããŒè¦‹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚",
                "å°‚é–€å®¶ã¯ã€Œã“ã‚Œã¾ã§ã«ãªã„ç”»æœŸçš„ãªæŠ€è¡“ã€ã¨è©•ä¾¡ã€‚",
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã¯æœŸå¾…ã¨ä¸å®‰ã®å£°ãŒæ··åœ¨ã—ã¦ã„ã‚‹ã€‚",
                "ç«¶åˆä»–ç¤¾ã‚‚å¯¾å¿œç­–ã‚’æ¤œè¨ã—å§‹ã‚ã¦ã„ã‚‹ã¨ã„ã†ã€‚"
            ],
            'ç·åˆ': [
                "ã“ã®ç™ºè¡¨ã«ã‚ˆã‚Šã€ç¤¾ä¼šå…¨ä½“ã«å¤§ããªå½±éŸ¿ãŒäºˆæƒ³ã•ã‚Œã‚‹ã€‚",
                "å°‚é–€å®¶ã¯ã€Œæ…é‡ãªå¯¾å¿œãŒå¿…è¦ã€ã¨æŒ‡æ‘˜ã—ã¦ã„ã‚‹ã€‚",
                "å›½æ°‘ã‹ã‚‰ã¯æ§˜ã€…ãªæ„è¦‹ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã‚‹ã€‚",
                "æ”¿åºœã‚‚è©³ç´°ãªæ¤œè¨ã‚’é€²ã‚ã¦ã„ã‚‹ã¨ã®ã“ã¨ã ã€‚"
            ]
        }
        
        contexts = category_contexts.get(category, category_contexts['ç·åˆ'])
        
        content_parts = [
            f"ã€{title.split('ã€')[1].split('ã€‘')[0] if 'ã€' in title else 'ãƒ‹ãƒ¥ãƒ¼ã‚¹'}ã€‘ã¨ã—ã¦æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹ä»Šå›ã®ä»¶ã«ã¤ã„ã¦ã€è©³ç´°ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚",
            "",
            random.choice(contexts),
            "",
            "é–¢ä¿‚è€…ã®è©±ã«ã‚ˆã‚‹ã¨ã€ã“ã®å‹•ãã¯ä»¥å‰ã‹ã‚‰æ°´é¢ä¸‹ã§é€²ã‚ã‚‰ã‚Œã¦ã„ãŸã¨ã„ã†ã€‚ã€Œå¤šãã®äººã«å½±éŸ¿ã‚’ä¸ãˆã‚‹é‡è¦ãªæ±ºå®šã€ã¨ã—ã¦ã€æ…é‡ã«æ¤œè¨ãŒé‡ã­ã‚‰ã‚Œã¦ããŸçµŒç·¯ãŒã‚ã‚‹ã€‚",
            "",
            "ç‰¹ã«æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã®ã¯ã€ä»Šå¾Œã®å±•é–‹ã«ã¤ã„ã¦ã§ã‚ã‚‹ã€‚å°‚é–€å®¶ã¯ã€Œã“ã‚Œã¾ã§ã®å¸¸è­˜ã‚’è¦†ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¨åˆ†æã—ã¦ãŠã‚Šã€æ¥­ç•Œå…¨ä½“ã¸ã®æ³¢åŠåŠ¹æœãŒæœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚",
            "",
            "ä¸€æ–¹ã§ã€èª²é¡Œã‚‚æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚ã€Œè§£æ±ºã™ã¹ãå•é¡ŒãŒã¾ã æ®‹ã£ã¦ã„ã‚‹ã€ã¨ã®å£°ã‚‚ã‚ã‚Šã€é–¢ä¿‚è€…ã¯æ…é‡ãªå¯¾å¿œã‚’ç¶šã‘ã¦ã„ã‚‹çŠ¶æ³ã ã€‚",
            "",
            "SNSä¸Šã§ã¯æ§˜ã€…ãªåå¿œãŒè¦‹ã‚‰ã‚Œã¦ãŠã‚Šã€ã€Œé©šã„ãŸã€ã€ŒæœŸå¾…ã—ã¦ã„ã‚‹ã€ã€Œå¿ƒé…ã ã€ãªã©ã€å¤šæ§˜ãªæ„è¦‹ãŒäº¤ã‚ã•ã‚Œã¦ã„ã‚‹ã€‚",
            "",
            "ä»Šå¾Œã®å‹•å‘ã«ã¤ã„ã¦ã€é–¢ä¿‚è€…ã¯ã€Œé©åˆ‡ãªæ™‚æœŸã«è©³ç´°ã‚’ç™ºè¡¨ã™ã‚‹äºˆå®šã€ã¨ã—ã¦ãŠã‚Šã€ç¶šå ±ãŒå¾…ãŸã‚Œã¦ã„ã‚‹çŠ¶æ³ã§ã‚ã‚‹ã€‚"
        ]
        
        return "\n".join(content_parts)
    
    def _generate_article_id(self, title: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().isoformat()
        hash_input = f"{title}{timestamp}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]
    
    def save_generated_articles(self) -> bool:
        """ç”Ÿæˆã—ãŸè¨˜äº‹ã‚’ä¿å­˜"""
        try:
            data_dir = Path('.')
            articles_file = data_dir / 'viral_articles.json'
            
            # æ—¢å­˜ã®è¨˜äº‹ã‚’èª­ã¿è¾¼ã‚€
            existing_articles = []
            if articles_file.exists():
                with open(articles_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    existing_articles = data.get('articles', [])
            
            # æ–°ã—ã„è¨˜äº‹ã‚’è¿½åŠ 
            existing_articles.extend(self.generated_articles)
            
            # æœ€æ–°ã®50è¨˜äº‹ã®ã¿ä¿æŒ
            existing_articles = existing_articles[-50:]
            
            # ä¿å­˜
            save_data = {
                'last_updated': datetime.now(timezone.utc).isoformat(),
                'total_articles': len(existing_articles),
                'articles': existing_articles
            }
            
            with open(articles_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Saved {len(self.generated_articles)} new articles to {articles_file}")
            return True
            
        except Exception as e:
            logger.error(f"Error saving generated articles: {e}")
            return False
    
    def get_article_performance_prediction(self, article: Dict) -> Dict:
        """è¨˜äº‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬"""
        score = 0
        factors = []
        
        title = article.get('title', '')
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢
        viral_keywords = article.get('viral_keywords', [])
        keyword_score = len([kw for kw in viral_keywords if kw in title]) * 20
        score += keyword_score
        if keyword_score > 0:
            factors.append(f"ãƒã‚¤ãƒ©ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨ (+{keyword_score})")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢
        if 'ã€' in title and 'ã€‘' in title:
            score += 15
            factors.append("ã€ã€‘å¼·èª¿ä½¿ç”¨ (+15)")
        
        if any(char in title for char in ['ï¼', '!', 'ï¼Ÿ', '?']):
            score += 10
            factors.append("æ„Ÿå˜†ç¬¦/ç–‘å•ç¬¦ä½¿ç”¨ (+10)")
        
        # æ•°å­—ã®ä½¿ç”¨
        import re
        if re.search(r'\d+', title):
            score += 10
            factors.append("æ•°å­—ä½¿ç”¨ (+10)")
        
        # ã‚¿ã‚¤ãƒˆãƒ«é•·
        title_length = len(title)
        if 35 <= title_length <= 45:
            score += 15
            factors.append("æœ€é©ãªã‚¿ã‚¤ãƒˆãƒ«é•· (+15)")
        
        # äºˆæ¸¬çµæœ
        performance_level = "ä½"
        if score >= 60:
            performance_level = "éå¸¸ã«é«˜ã„"
        elif score >= 45:
            performance_level = "é«˜ã„"
        elif score >= 30:
            performance_level = "ä¸­"
        
        return {
            'score': score,
            'level': performance_level,
            'factors': factors,
            'recommendation': self._get_recommendation(score)
        }
    
    def _get_recommendation(self, score: int) -> str:
        """ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ãŸæ”¹å–„ææ¡ˆ"""
        if score >= 60:
            return "ã“ã®ã‚¿ã‚¤ãƒˆãƒ«ã¯é«˜ã„ãƒã‚¤ãƒ©ãƒ«æ€§ãŒæœŸå¾…ã§ãã¾ã™ã€‚SNSã§ã®æ‹¡æ•£ã‚’ç‹™ã„ã¾ã—ã‚‡ã†ã€‚"
        elif score >= 45:
            return "è‰¯ã„ã‚¿ã‚¤ãƒˆãƒ«ã§ã™ã€‚ç”»åƒã‚„å‹•ç”»ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«åŠ¹æœçš„ã«ãªã‚Šã¾ã™ã€‚"
        elif score >= 30:
            return "ã‚‚ã†å°‘ã—ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚"
        else:
            return "ã‚ˆã‚Šæ„Ÿæƒ…ã«è¨´ãˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã€ã€‘ã§ã®å¼·èª¿ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"


def main():
    """Main execution function"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    try:
        generator = ViralArticleGenerator()
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã«åŸºã¥ã„ã¦è¨˜äº‹ç”Ÿæˆ
        logger.info("ğŸš€ Generating viral articles based on ranking analysis...")
        articles = generator.generate_trending_articles(num_articles=5)
        
        if articles:
            # è¨˜äº‹ã‚’ä¿å­˜
            generator.save_generated_articles()
            
            # çµæœè¡¨ç¤º
            print(f"\nâœ… Generated {len(articles)} viral articles:")
            for article in articles:
                print(f"\nğŸ“° {article['title']}")
                print(f"   Category: {article['category']}")
                print(f"   Keywords: {', '.join(article.get('viral_keywords', []))}")
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
                prediction = generator.get_article_performance_prediction(article)
                print(f"   Performance: {prediction['level']} (Score: {prediction['score']})")
                print(f"   Factors: {', '.join(prediction['factors'])}")
            
            print("\nğŸ‰ Viral article generation completed!")
        else:
            print("\nâŒ No articles were generated")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Fatal error: {str(e)}")
        raise


if __name__ == "__main__":
    main()